{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling of US Suicide Deaths\n",
    "Capstone Project for M.S. Data Analytics Program\n",
    "\n",
    "Melissa Stone Rogers, [GitHub](https://github.com/meldstonerogers/capstone-stonerogers), April 4, 2025\n",
    "\n",
    "## Introduction \n",
    "This is a professional project exaiming trends in suicide over time. Data has been gathered from Center for Disease Control using\n",
    "the Wide-ranging ONline Data for Epidemiologic Research[(WONDER)](https://wonder.cdc.gov) system. \n",
    "\n",
    "Commands were used on a Mac machine running zsh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7106 entries, 0 to 7105\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   state            7106 non-null   object\n",
      " 1   state_code       7106 non-null   int64 \n",
      " 2   age_group_years  7106 non-null   int64 \n",
      " 3   sex              7106 non-null   int64 \n",
      " 4   race             7106 non-null   object\n",
      " 5   race_code        7106 non-null   int64 \n",
      " 6   year             7106 non-null   int64 \n",
      " 7   deaths           7106 non-null   int64 \n",
      " 8   population       7106 non-null   int64 \n",
      "dtypes: int64(7), object(2)\n",
      "memory usage: 499.8+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/cleaned_data.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Data Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  5684 Test size:  1422\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(df,\n",
    "                        test_size=0.2, random_state=123)\n",
    "print('Train size: ', len(train_set), 'Test size: ', len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate Linear Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for linear regression on training data\n",
      "  Default settings\n",
      "Internal parameters:\n",
      "   Bias is  -96.00559296275848\n",
      "   Coefficients [1.25845476e-01 4.19552460e+01 7.29870907e+00 1.58547912e-04]\n",
      "   Score 0.6330167640008322\n",
      "MAE is   15.571962860140275\n",
      "RMSE is  23.35370072974408\n",
      "MSE is  545.3953377744491\n",
      "R^2     0.6330167640008322\n",
      "\n",
      "Results for linear regression on test data\n",
      "MAE is   15.140016736685686\n",
      "RMSE is  22.089473187792617\n",
      "MSE is  487.94482571420895\n",
      "R^2     0.6842941207645077\n",
      "\n",
      "Model saved to 'models/lr_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import pickle\n",
    "\n",
    "X_train = train_set[['age_group_years', 'sex', 'race_code', 'population']]\n",
    "y_train = train_set['deaths']\n",
    "\n",
    "X_test = test_set[['age_group_years', 'sex', 'race_code', 'population']]\n",
    "y_test = test_set['deaths']\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = lr_model.predict(X_train)\n",
    "print('Results for linear regression on training data')\n",
    "print('  Default settings')\n",
    "print('Internal parameters:')\n",
    "print('   Bias is ', lr_model.intercept_)\n",
    "print('   Coefficients', lr_model.coef_)\n",
    "print('   Score', lr_model.score(X_train,y_train))\n",
    "print('MAE is  ', mean_absolute_error(y_train, y_pred))\n",
    "print('RMSE is ', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "print('MSE is ', mean_squared_error(y_train, y_pred))\n",
    "print('R^2    ', r2_score(y_train,y_pred))\n",
    "\n",
    "y_test_pred = lr_model.predict(X_test)\n",
    "print()\n",
    "print('Results for linear regression on test data')\n",
    "print('MAE is  ', mean_absolute_error(y_test, y_test_pred))\n",
    "print('RMSE is ', np.sqrt(mean_squared_error(y_test,\n",
    "y_test_pred)))\n",
    "print('MSE is ', mean_squared_error(y_test, y_test_pred))\n",
    "print('R^2    ', r2_score(y_test,y_test_pred))\n",
    "\n",
    "# Save the trained model to a pickle file\n",
    "lr_model_path = 'models/lr_model.pkl'\n",
    "with open(lr_model_path, 'wb') as f:  \n",
    "    pickle.dump(lr_model, f)\n",
    "\n",
    "print(f\"\\nModel saved to '{lr_model_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for training data with Random Forest Regressor\n",
      "MAE is   15.571962860140275\n",
      "RMSE is  23.35370072974408\n",
      "MSE is  545.3953377744491\n",
      "R^2     0.6330167640008322\n",
      "Results for test data with Random Forest Regressor\n",
      "MAE is   17.765812577116282\n",
      "RMSE is  24.017492249213614\n",
      "MSE is  576.839933941036\n",
      "R^2     0.6267779697090966\n",
      "\n",
      "Model saved to 'regr.pkl'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "\n",
    "X_train = train_set[['age_group_years', 'sex', 'race_code', 'population']]\n",
    "y_train = train_set['deaths']\n",
    "\n",
    "X_test = test_set[['age_group_years', 'sex', 'race_code', 'population']]\n",
    "y_test = test_set['deaths']\n",
    "\n",
    "# Fit the model on training data\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate on training data\n",
    "y_train_pred = regr.predict(X_train)\n",
    "print('Results for training data with Random Forest Regressor')\n",
    "print('MAE is  ', mean_absolute_error(y_train, y_pred))\n",
    "print('RMSE is ', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "print('MSE is ', mean_squared_error(y_train, y_pred))\n",
    "print('R^2    ', r2_score(y_train, y_pred))\n",
    "\n",
    "# Predict and evaluate on test data\n",
    "y_test_pred = regr.predict(X_test)\n",
    "print('Results for test data with Random Forest Regressor')\n",
    "print('MAE is  ', mean_absolute_error(y_test, y_test_pred))\n",
    "print('RMSE is ', np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print('MSE is ', mean_squared_error(y_test, y_test_pred))\n",
    "print('R^2    ', r2_score(y_test, y_test_pred))\n",
    "\n",
    "# Save the trained model to a pickle file\n",
    "regr = 'models/regr.pkl'\n",
    "with open(regr, 'wb') as f:  # Save model to file\n",
    "    pickle.dump(regr, f)\n",
    "\n",
    "print(\"\\nModel saved to 'regr.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Decision Tree Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.7123769338959213\n",
      "\n",
      "Classification Report on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.77      0.78      0.77       346\n",
      "         Low       0.63      0.63      0.63       341\n",
      "      Medium       0.72      0.72      0.72       735\n",
      "\n",
      "    accuracy                           0.71      1422\n",
      "   macro avg       0.71      0.71      0.71      1422\n",
      "weighted avg       0.71      0.71      0.71      1422\n",
      "\n",
      "\n",
      "Feature Importances:\n",
      "age_group_years: 0.1534313484439139\n",
      "sex: 0.15924502752756703\n",
      "race_code: 0.06016835293677794\n",
      "year: 0.09539740509612805\n",
      "population: 0.5317578659956133\n",
      "\n",
      "Confusion Matrix on Test Data:\n",
      "[[270   0  76]\n",
      " [  2 214 125]\n",
      " [ 80 126 529]]\n",
      "\n",
      "Model saved to clf.pkl'\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Assuming 'df' is your dataset\n",
    "# Categorize 'deaths' into Low, Medium, and High\n",
    "df['death_category'] = np.where(df['deaths'] < 15, 'Low',\n",
    "                                np.where(df['deaths'] <= 47, 'Medium', 'High'))\n",
    "\n",
    "\n",
    "# Use numeric features for classification \n",
    "X = df[['age_group_years', 'sex', 'race_code', 'year', 'population']]  \n",
    "y = df['death_category']\n",
    "\n",
    "# Stratified split to preserve percentage of each class in train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the training and test data\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"Training Accuracy: \", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Test Accuracy: \", accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# Print a detailed classification report\n",
    "print(\"\\nClassification Report on Test Data:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Feature importance - Identify which variables matter most in predicting death category\n",
    "feature_importances = clf.feature_importances_\n",
    "print(\"\\nFeature Importances:\")\n",
    "for feature, importance in zip(X.columns, feature_importances):\n",
    "    print(f\"{feature}: {importance}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix on Test Data:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "# Save the trained model to a pickle file\n",
    "clf = 'models/clf_model.pkl'\n",
    "with open(clf, 'wb') as f:  # Save model to file\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "print(\"\\nModel saved to clf.pkl'\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Training Accuracy:  1.0\n",
      "Random Forest - Test Accuracy:  0.7461322081575246\n",
      "\n",
      "Random Forest - Classification Report on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.82      0.84      0.83       346\n",
      "         Low       0.65      0.63      0.64       341\n",
      "      Medium       0.75      0.75      0.75       735\n",
      "\n",
      "    accuracy                           0.75      1422\n",
      "   macro avg       0.74      0.74      0.74      1422\n",
      "weighted avg       0.74      0.75      0.75      1422\n",
      "\n",
      "\n",
      "Random Forest - Feature Importances:\n",
      "age_group_years: 0.14013343936798117\n",
      "sex: 0.13658922366409074\n",
      "race_code: 0.047425309053392276\n",
      "year: 0.08189632688896195\n",
      "population: 0.5939557010255739\n",
      "\n",
      "Random Forest - Confusion Matrix on Test Data:\n",
      "[[291   0  55]\n",
      " [  0 216 125]\n",
      " [ 66 115 554]]\n",
      "\n",
      "Model saved to 'rf_clf.pkl'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the training and test data\n",
    "y_train_pred_rf = rf_clf.predict(X_train)\n",
    "y_test_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"Random Forest - Training Accuracy: \", accuracy_score(y_train, y_train_pred_rf))\n",
    "print(\"Random Forest - Test Accuracy: \", accuracy_score(y_test, y_test_pred_rf))\n",
    "\n",
    "# Print a detailed classification report\n",
    "print(\"\\nRandom Forest - Classification Report on Test Data:\")\n",
    "print(classification_report(y_test, y_test_pred_rf))\n",
    "\n",
    "# Feature importance from Random Forest\n",
    "rf_feature_importances = rf_clf.feature_importances_\n",
    "print(\"\\nRandom Forest - Feature Importances:\")\n",
    "for feature, importance in zip(X.columns, rf_feature_importances):\n",
    "    print(f\"{feature}: {importance}\")\n",
    "\n",
    "print(\"\\nRandom Forest - Confusion Matrix on Test Data:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_rf))\n",
    "\n",
    "# Save the trained model to a pickle file\n",
    "rf_clf = 'models/rf_clf_model.pkl'\n",
    "with open(rf_clf, 'wb') as f:  # Save model to file\n",
    "    pickle.dump(rf_clf, f)\n",
    "\n",
    "print(\"\\nModel saved to 'rf_clf.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "Basic results for models to predict deaths based on cleaned suicide dataset.\n",
    "| Model | Training Features | Set | RMSE | R2 |\n",
    "|:---|:---|:---|:---|:---|\n",
    "|Linear Regression|age_group_years, sex, race_code|Training|35.89|13.31|\n",
    "|Linear Regression|age_group_years, sex, race_code|Test|36.76|12.59|\n",
    "|Linear Regression|age_group_years, sex, race_code, population|Training|23.35|63.30|\n",
    "|Linear Regression|age_group_years, sex, race_code, population|Test|22.10|68.43|\n",
    "|Random Forest Regressor|age_group_years, sex, race_code|Training|35.889|13.31|\n",
    "|Random Forest Regressor|age_group_years, sex, race_code|Test|36.44|14.10|\n",
    "|Random Forest Regressor|age_group_years, sex, race_code, population|Training|23.35|63.30|\n",
    "|Random Forest Regressor|age_group_years, sex, race_code, population|Test|24.02|62.68|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic results for models to predict feature importance based on cleaned suicide dataset. \n",
    "| Model | Training Features | Set | Accuracy | \n",
    "|:---|:---|:---|:---|\n",
    "|Decision Tree Model|age_group_years, sex, race_code, population|Training|1.0|\n",
    "|Decision Tree Model|age_group_years, sex, race_code, population|Test|.71|\n",
    "|Random Forest Model|age_group_years, sex, race_code, population|Training|1.0|\n",
    "|Random Forest Model|age_group_years, sex, race_code, population|Test|.75|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree Classifier Feature Importance**\n",
    "| Feature | Feature Importance |\n",
    "|:---|:---|\n",
    "|age_group_years|0.15|\n",
    "|sex|0.14|\n",
    "|race_code|.06|\n",
    "|year|0.10|\n",
    "|population|0.53|\n",
    "\n",
    "**Random Forest Feature Importance**\n",
    "| Feature | Feature Importance |\n",
    "|:---|:---|\n",
    "|age_group_years|0.14|\n",
    "|sex|0.14|\n",
    "|race_code|.05|\n",
    "|year|0.08|\n",
    "|population|0.59|\n",
    "\n",
    "**Decision Tree Classifier Confusion Matrix**\n",
    "| Predicted \\ Actual | Low  | Medium | High |\n",
    "|:---|:---|:---|:---|\n",
    "| Low                | 270  | 0      | 76   |\n",
    "| Medium             | 2    | 214    | 125  |\n",
    "| High               | 80   | 126    | 529  |\n",
    "\n",
    "\n",
    "**Random Tree Confusion Matrix**\n",
    "| Predicted \\ Actual | Low  | Medium | High |\n",
    "|:---|:---|:---|:---|\n",
    "| Low                | 291 | 0      | 55   |\n",
    "| Medium             | 0    | 216    | 125  |\n",
    "| High               | 66   | 115    | 524  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion of Results\n",
    "The initial linear regression model performed poorly on both training and test sets noted by relatively high errors and very low R^2. This model does not fit well to the data. When \"population\" was added to the linear regression model, the RMSE improved and the R^2 increased significantly. This suggests \"population\" may be important in predicting the number of deaths. However, further analysis is needed to determine if the rate of death is proportional to the size of the population.\n",
    "\n",
    "The Random Forest Regressor model's initial training and test sets were very similar to the initial linear regression models. Similar to the linear regression model, with the inclusion of \"population\" into the variables, the Random Forest Regressor performed better. However, when including population, the linear regression model's test model performed better.\n",
    "\n",
    "When considering predicting the number of deaths, a linear regression model with all features is the best performing model. It is possible the data is not complex enough for the Random Forest Regressor model to offer a performance advantage.\n",
    "\n",
    "The Decision Tree Classifier Model performed well on the training set with 100% accuracy, which suggests the model is overfitting. The test set performed okay, with 71% accuracy, but this is not generalizable to other data. The Decision Tree Classifier confusion matrix shows the model was good at classifying the \"High\" death category; the \"High\" category may be overemphasized in this model.\n",
    "\n",
    "The Random Forest Classifier also had 100% accuracy on the training set, which again suggests overfitting. The test set performed better than the Decision Tree Classifier's test set with 75%, which is still not great for generalizability, but still better than the Decision Tree Classifier.\n",
    "Regarding the Random Forest Classifiers, the confusion matrix did not do well in classifying \"High\" or \"Low\" categories, again suggesting the Decision Tree Classifier as the better performing model when deciding feature importance in death prediction.\n",
    "\n",
    "Both classifier models note \"population\" as the most important feature, followed by \"sex\" and \"age_group_years.\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
