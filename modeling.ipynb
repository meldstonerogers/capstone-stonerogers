{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling of US Suicide Deaths\n",
    "Capstone Project for M.S. Data Analytics Program\n",
    "\n",
    "Melissa Stone Rogers, [GitHub](https://github.com/meldstonerogers/capstone-stonerogers), April 4, 2025\n",
    "\n",
    "## Introduction \n",
    "This is a professional project exaiming trends in suicide over time. Data has been gathered from Center for Disease Control using\n",
    "the Wide-ranging ONline Data for Epidemiologic Research[(WONDER)](https://wonder.cdc.gov) system. \n",
    "\n",
    "Commands were used on a Mac machine running zsh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7106 entries, 0 to 7105\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   state            7106 non-null   object\n",
      " 1   state_code       7106 non-null   int64 \n",
      " 2   age_group_years  7106 non-null   int64 \n",
      " 3   sex              7106 non-null   int64 \n",
      " 4   race             7106 non-null   object\n",
      " 5   race_code        7106 non-null   int64 \n",
      " 6   year             7106 non-null   int64 \n",
      " 7   deaths           7106 non-null   int64 \n",
      " 8   population       7106 non-null   int64 \n",
      "dtypes: int64(7), object(2)\n",
      "memory usage: 499.8+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/cleaned_data.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'autompg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mautompg\u001b[49m.head(n=\u001b[32m10\u001b[39m))\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(autompg.describe())\n",
      "\u001b[31mNameError\u001b[39m: name 'autompg' is not defined"
     ]
    }
   ],
   "source": [
    "print(autompg.head(n=10))\n",
    "print(autompg.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Data Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  318 Test size:  80\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(autompg,\n",
    "                        test_size=0.2, random_state=123)\n",
    "print('Train size: ', len(train_set), 'Test size: ', len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate a Linear Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for linear regression on training data\n",
      "  Default settings\n",
      "Internal parameters:\n",
      "   Bias is  43.621433976443285\n",
      "   Coefficients [-0.00556012 -0.01801839]\n",
      "   Score 0.7024820582511935\n",
      "MAE is   3.2290037032091603\n",
      "RMSE is  4.2789696537676765\n",
      "MSE is  18.309581297864668\n",
      "R^2     0.7024820582511935\n",
      "\n",
      "Results for linear regression on test data\n",
      "MAE is   3.4980689722029554\n",
      "RMSE is  4.343131313113012\n",
      "MSE is  18.862789602942755\n",
      "R^2     0.6765950182605451\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X = train_set[['weight', 'displacement']]\n",
    "y = train_set['mpg']\n",
    "\n",
    "X_test = test_set[['weight', 'displacement']]\n",
    "y_test = test_set['mpg']\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X,y)\n",
    "\n",
    "y_pred = lr_model.predict(X)\n",
    "print('Results for linear regression on training data')\n",
    "print('  Default settings')\n",
    "print('Internal parameters:')\n",
    "print('   Bias is ', lr_model.intercept_)\n",
    "print('   Coefficients', lr_model.coef_)\n",
    "print('   Score', lr_model.score(X,y))\n",
    "print('MAE is  ', mean_absolute_error(y, y_pred))\n",
    "print('RMSE is ', np.sqrt(mean_squared_error(y, y_pred)))\n",
    "print('MSE is ', mean_squared_error(y, y_pred))\n",
    "print('R^2    ', r2_score(y,y_pred))\n",
    "\n",
    "y_test_pred = lr_model.predict(X_test)\n",
    "print()\n",
    "print('Results for linear regression on test data')\n",
    "print('MAE is  ', mean_absolute_error(y_test, y_test_pred))\n",
    "print('RMSE is ', np.sqrt(mean_squared_error(y_test,\n",
    "y_test_pred)))\n",
    "print('MSE is ', mean_squared_error(y_test, y_test_pred))\n",
    "print('R^2    ', r2_score(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stage bias is  23.412578616352203\n",
      "The stage feature coefficients are  [-4.76109404 -1.88955493]\n",
      "Results for linear regression on training data with pipeline\n",
      "MAE is   3.229003703209161\n",
      "RMSE is  4.2789696537676765\n",
      "MSE is  18.309581297864668\n",
      "R^2     0.7024820582511935\n",
      "Results for linear regression on test data with pipeline\n",
      "MAE is   3.4980689722029568\n",
      "RMSE is  4.3431313131130125\n",
      "MSE is  18.862789602942758\n",
      "R^2     0.676595018260545\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Define the pipline\n",
    "autompg_pipe = Pipeline([\n",
    "    ('median_transform', SimpleImputer(strategy='median')),\n",
    "    ('scale_transform', StandardScaler()),\n",
    "    ('lin_reg', LinearRegression())])\n",
    "\n",
    "# Fit the pipeline\n",
    "autompg_pipe.fit(X,y)\n",
    "\n",
    "# Output the intercept and coefficients \n",
    "print(\"The stage bias is \" ,\n",
    "      autompg_pipe.named_steps['lin_reg'].intercept_)\n",
    "print(\"The stage feature coefficients are \",\n",
    "      autompg_pipe.named_steps['lin_reg'].coef_)\n",
    "\n",
    "# Predict and evaluate on training data\n",
    "y_pred = autompg_pipe.predict(X)\n",
    "print('Results for linear regression on training data with pipeline')\n",
    "print('MAE is  ', mean_absolute_error(y, y_pred))\n",
    "print('RMSE is ', np.sqrt(mean_squared_error(y, y_pred)))\n",
    "print('MSE is ', mean_squared_error(y, y_pred))\n",
    "print('R^2    ', r2_score(y, y_pred))\n",
    "\n",
    "# Predict and evaluate on test data\n",
    "y_test_pred = autompg_pipe.predict(X_test)\n",
    "print('Results for linear regression on test data with pipeline')\n",
    "print('MAE is  ', mean_absolute_error(y_test, y_test_pred))\n",
    "print('RMSE is ', np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print('MSE is ', mean_squared_error(y_test, y_test_pred))\n",
    "print('R^2    ', r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stage bias is  23.412578616352206\n",
      "The stage feature coefficients are  [  0.          -1.49502986 -14.1635106  -11.16752447  24.49126934\n",
      "  -4.53461007]\n",
      "Results for linear regression with polynomial features on training data with pipeline\n",
      "MAE is   2.9597527898224114\n",
      "RMSE is  4.053977013800068\n",
      "MSE is  16.43472962841932\n",
      "R^2     0.7329470918695618\n",
      "Results for linear regression with polynomial features on test data with pipeline\n",
      "MAE is   3.1805704976155433\n",
      "RMSE is  4.284941459858176\n",
      "MSE is  18.360723314411516\n",
      "R^2     0.6852030100948552\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "power = 3\n",
    "poly_process = PolynomialFeatures(degree=power, include_bias=False)\n",
    "\n",
    "#Define the pipeline\n",
    "autompg_pipe = Pipeline([\n",
    "    ('median_transform', SimpleImputer(strategy='median')), \n",
    "    ('poly_process', PolynomialFeatures()),\n",
    "    ('scale_transform', StandardScaler()),\n",
    "    ('lin_reg', LinearRegression())])\n",
    "\n",
    "# Fit the pipeline\n",
    "autompg_pipe.fit(X,y)\n",
    "\n",
    "# Output the intercept and coefficients \n",
    "print(\"The stage bias is \" ,\n",
    "      autompg_pipe.named_steps['lin_reg'].intercept_)\n",
    "print(\"The stage feature coefficients are \",\n",
    "      autompg_pipe.named_steps['lin_reg'].coef_)\n",
    "\n",
    "# Predict and evaluate on training data\n",
    "y_pred = autompg_pipe.predict(X)\n",
    "print('Results for linear regression with polynomial features on training data with pipeline')\n",
    "print('MAE is  ', mean_absolute_error(y, y_pred))\n",
    "print('RMSE is ', np.sqrt(mean_squared_error(y, y_pred)))\n",
    "print('MSE is ', mean_squared_error(y, y_pred))\n",
    "print('R^2    ', r2_score(y, y_pred))\n",
    "\n",
    "# Predict and evaluate on test data\n",
    "y_test_pred = autompg_pipe.predict(X_test)\n",
    "print('Results for linear regression with polynomial features on test data with pipeline')\n",
    "print('MAE is  ', mean_absolute_error(y_test, y_test_pred))\n",
    "print('RMSE is ', np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print('MSE is ', mean_squared_error(y_test, y_test_pred))\n",
    "print('R^2    ', r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "Basic results for models to predict mpg on\n",
    "the auto-mpg data.\n",
    "| Model | Training Features | Set | RMSE | R2 |\n",
    "|:---|:---|:---|:---|:---|\n",
    "|Linear Regression|Weight,Displacement|Training|4.28|70.25|\n",
    "|Linear Regression|Weight,Displacement|Test|4.34|67.67|\n",
    "|Pipeline, Linear Regression|Weight,Displacement|Training|4.28|70.25|\n",
    "|Pipeline, Linear Regression|Weight,Displacement|Test|4.34|67.67|\n",
    "|Pipeline with Polynomial Features, Linear Regression|Weight,Displacement|Training|4.05|73.29|\n",
    "|Pipeline with Polynomial Features, Linear Regression|Weight,Displacement|Test|4.28|68.52|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion of Results\n",
    "The performance of the models improved with each iteration, the pipeline model with the polynomial features performing the best. However, none of the models performed spectacularly- none of the R^2 scores were close to 80%. I do not have a concern of over- or under-fitting on any of the models, as the test models vs the training models performed as expected. I even ran the polynomial pipeline with a higher power and saw no discernable difference in model performance. I think my chosen features are not the best features to predict the target feature, mpg. \n",
    "\n",
    "I was curious, so I duplicated the notebook to run the other features. I still believe that weight is an important feature as it relates to mpg, so I then changed my secondary feature. Cylinders, acceleration, and origin had similar performance numbers as displacement. \n",
    "\n",
    "However, the pipeline with polynomial features, using weight and model year as my training features had significantly improved scores: training RMSE, 2.91 and R^2, 86.26%; test RMSE, 2.11 and R^2, 85.88%. I would imagine this could be due to advancements in car engineering allowing for a more effective use of fuel, thus having better mpg. The advancements that occurred as model years increased must have a strong correlation to the mpg, allowing this variable to be an important predictive feature.   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
